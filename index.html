<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>History of computer science</title>
</head>
<body>
    <h1>History of computer science</h1>
    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/Glen_Beck_and_Betty_Snyder_program_the_ENIAC_in_building_328_at_the_Ballistic_Research_Laboratory.jpg/500px-Glen_Beck_and_Betty_Snyder_program_the_ENIAC_in_building_328_at_the_Ballistic_Research_Laboratory.jpg" alt="computer" width="100" height="100">
    <P>The history of computer science began long before the modern discipline of computer science,
         usually appearing in forms like mathematics or physics.
          Developments in previous centuries alluded to the discipline that we now know as computer science.
           This progression, from mechanical inventions and mathematical theories towards modern computer concepts and machines, 
           led to the development of a major academic field, massive technological advancement across the Western world, and the basis of massive worldwide trade and culture</P>
         <h2>Prehistory<hr></h2>
         <img src="https://upload.wikimedia.org/wikipedia/commons/c/cc/John_Napier.JPG" width="100" height="100">
         <a href="/wiki/John_Napier" title="John Napier"><p>John Napier</a>
<p>The earliest known tool for use in computation was the abacus, developed in the period between 2700 and 2300 BCE in Sumer.
    The Sumerians' abacus consisted of a table of successive columns which delimited the successive orders of magnitude of their sexagesimal number system.
    Its original style of usage was by lines drawn in sand with pebbles. 
    Abaci of a more modern design are still used as calculation tools today, such as the Chinese abacus.</p>
    <h2>Binary logic</h2>
    <hr>
    <h3>Gottfried Wilhelm Leibniz</h3>
    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/8d/Christoph_Bernhard_Francke_-_Bildnis_des_Philosophen_Leibniz_%28ca._1695%29.jpg/330px-Christoph_Bernhard_Francke_-_Bildnis_des_Philosophen_Leibniz_%28ca._1695%29.jpg" alt="Gottfried Wilhelm Leibniz" width="100" height="100">
    <p >In 1702, Gottfried Wilhelm Leibniz developed logic in a formal,
         mathematical sense with his writings on the binary numeral system.
          Leibniz simplified the binary system and articulated logical properties such as conjunction, 
          disjunction, negation, identity, inclusion, and the empty set.
           He anticipated Lagrangian interpolation and algorithmic information theory. 
           His calculus ratiocinator anticipated aspects of the universal Turing machine.
            In 1961, Norbert Wiener suggest</tabled that Leibniz should be considered the patron saint of cybernetics</p>
           <h2>Emergence of a discipline</h2>
           <hr>
           <span>
           <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Portrait_of_Charles_Babbage_%284672397%29.jpg/500px-Portrait_of_Charles_Babbage_%284672397%29.jpg" height="100" width="100">
          <h3>Charles Babbage and Ada Lovelace</h3>
           <p>ain articles: Charles Babbage and Ada Lovelace<br>

Charles Babbage is often regarded as one of the first pioneers of computing.<br>
 Beginning in the 1810s, Babbage had a vision of mechanically computing numbers and tables..<br>
  Putting this into reality, Babbage designed a calculator to compute numbers up to 8 decimal points long..<br>
   Continuing with the success of this idea, Babbage worked to develop a machine that could compute numbers with up to 20 decimal places.
    By the 1830s,.<br>
    Babbage had devised a plan to develop a machine that could use punched cards to perform arithmetical operations..<br>
     The machine would store numbers in memory units, and there would be a form of sequential control. 
     .<br>This means that one operation would be carried out before another in such a way that the machine would produce an answer and not fail.</p>
           </span>
           <h2>Generation of computer </h2>
            <table border="1">
            <th colspan="5">computer generation </th>
        <tr>
            <td><b>Generation</b></td>
            <td><b>Time Period</b></td>
            <td><b>Main Technology Used</b></td>
            <td><b>Key Features</b></td>
            <td><b>Examples</b></td>
            </tr>
        <hr>
        <tr>
            <td>First Generation</td>
            <td>1940–1956</td>
            <td>Vacuum Tubes</td>
            <td>Very large size, high power consumption, produced a lot of heat, machine language only</td>
            <td>ENIAC, UNIVAC I</td>
        </tr>
        <tr>
            <td>Second Generation</td>
            <td>1956–1963</td>
            <td>Transistors</td>
            <td>Smaller than first gen, less heat, more reliable, assembly language used</td>
            <td>IBM 1401, IBM 7094</td>
        </tr>
        <tr>
            <td>Third Generation</td>
            <td>1964–1971</td>
            <td>Integrated Circuits (ICs)</td>
            <td>Smaller size, faster processing, lower power consumption, high-level languages</td>
            <td>IBM System/360</td>
        </tr>
        <tr>
            <Td>Fourth Generation</Td>
            <Td>1971–Present</Td>
            <Td>Microprocessors</Td>
            <Td>Very small size, personal computers, high speed, low cost</Td>
            <Td>Intel 4004, IBM PC</Td>
        </tr>
        <tr>
            <td>Fifth Generation</td>
            <td>Present & Future</td>
            <td>Artificial Intelligence (AI)</td>
            <td>Machine learning, natural language processing, robotics</td>
            <td>AI systems, modern supercomputers</td>
        </tr> 
        </table>
        <h2>see also</h2>
<hr>
<ul>
    <li> <a href="https://en.wikipedia.org/wiki/Computer_museum"> computer museum</a></li>
    <li><a href="https://en.wikipedia.org/wiki/List_of_computer_term_etymologies"> List of computer term etymologies</a><p> the origins of computer science words</p> </li>
    <li><a href="https://en.wikipedia.org/wiki/List_of_pioneers_in_computer_science">List of pioneers in computer science</a></li>
    <li><a href="https://en.wikipedia.org/wiki/History_of_computing">History of computing</a></li>
    <li><a href="https://en.wikipedia.org/wiki/History_of_computing_hardware">History of comuting hardware</a></li>
    <li><a href="https://en.wikipedia.org/wiki/History_of_software">History of software</a></li>
    <li><a href="https://en.wikipedia.org/wiki/History_of_personal_computers">History of persional computer</a></li>
    <li><a href="https://en.wikipedia.org/wiki/Timeline_of_algorithms">Timeline of algorithm </a></li>
    <li><a href="https://en.wikipedia.org/wiki/Timeline_of_women_in_computing">Timeline of women in computer</a></li>
    <li><a href="https://en.wikipedia.org/wiki/Timeline_of_computing_2020%E2%80%93present">Timeline of computing 2020-present</a></li>

</ul>
    </body>
</html>
    